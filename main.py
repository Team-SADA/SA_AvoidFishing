# file: main.py
# ============================================
# âš¡ Voice Phishing Detection Unified System
# TF-IDF + KoBERT ê²°í•© (50% ì´ìƒ ì‹œ ì¶”ê°€ íŒë³„)
# ============================================

import os
import joblib
import torch
import numpy as np
from transformers import AutoTokenizer, AutoModelForSequenceClassification

# -------------------------------------------------------
# âš™ï¸ ì„¤ì •
# -------------------------------------------------------
MODEL_NAME = "skt/kobert-base-v1"
MAX_LEN = 96
DEVICE = torch.device("cuda" if torch.cuda.is_available() else "cpu")

# -------------------------------------------------------
# ğŸ“‚ ê²½ë¡œ ì„¤ì •
# -------------------------------------------------------
BASE_DIR = os.path.dirname(__file__)
MODEL_DIR = os.path.join(BASE_DIR, "outputs", "models")
TOKENIZER_DIR = os.path.join(BASE_DIR, "outputs", "tokenizer")
DANGER_PATH = os.path.join(BASE_DIR, "data", "processed", "danger_words.txt")

# -------------------------------------------------------
# ğŸ§© ìµœì‹  íŒŒì¼ ë¡œë“œ í•¨ìˆ˜
# -------------------------------------------------------
def get_latest_file(directory, prefix, extension):
    files = [f for f in os.listdir(directory) if f.startswith(prefix) and f.endswith(extension)]
    if not files:
        raise FileNotFoundError(f"{directory} ë‚´ì— {prefix} ê´€ë ¨ íŒŒì¼ì´ ì—†ìŠµë‹ˆë‹¤.")
    latest = max(files, key=lambda x: os.path.getctime(os.path.join(directory, x)))
    return os.path.join(directory, latest)

# -------------------------------------------------------
# ğŸ§  TF-IDF ëª¨ë¸ ë¡œë“œ
# -------------------------------------------------------
def load_tfidf_model():
    model_path = get_latest_file(MODEL_DIR, "tfidf", ".pkl")
    vectorizer_path = get_latest_file(TOKENIZER_DIR, "tfidf", ".pkl")

    model = joblib.load(model_path)
    vectorizer = joblib.load(vectorizer_path)

    print(f"âœ… TF-IDF ëª¨ë¸ ë¡œë“œ ì™„ë£Œ: {os.path.basename(model_path)}")
    print(f"âœ… TF-IDF ë²¡í„° ë¡œë“œ ì™„ë£Œ: {os.path.basename(vectorizer_path)}")

    return model, vectorizer

# -------------------------------------------------------
# ğŸ§  KoBERT ëª¨ë¸ ë¡œë“œ
# -------------------------------------------------------
def load_kobert_model():
    model_path = get_latest_file(MODEL_DIR, "kobert", ".pt")
    tokenizer = AutoTokenizer.from_pretrained(MODEL_NAME, use_fast=False, do_lower_case=False)
    model = AutoModelForSequenceClassification.from_pretrained(MODEL_NAME, num_labels=2)
    model.load_state_dict(torch.load(model_path, map_location=DEVICE))
    model.to(DEVICE)
    model.eval()

    print(f"âœ… KoBERT ëª¨ë¸ ë¡œë“œ ì™„ë£Œ: {os.path.basename(model_path)}")
    return tokenizer, model

# -------------------------------------------------------
# âš ï¸ ìœ„í—˜ ë‹¨ì–´ ë¡œë“œ
# -------------------------------------------------------
def load_danger_words():
    if os.path.exists(DANGER_PATH):
        with open(DANGER_PATH, "r", encoding="utf-8") as f:
            words = [line.strip() for line in f.readlines()]
        print(f"âš ï¸ ìœ„í—˜ ë‹¨ì–´ {len(words)}ê°œ ë¡œë“œ ì™„ë£Œ")
        return words
    print("âš ï¸ ìœ„í—˜ ë‹¨ì–´ íŒŒì¼ì´ ì—†ìŠµë‹ˆë‹¤. ê±´ë„ˆëœë‹ˆë‹¤.")
    return []

# -------------------------------------------------------
# ğŸ” TF-IDF ì˜ˆì¸¡
# -------------------------------------------------------
def predict_tfidf(text, model, vectorizer, danger_words):
    text_vec = vectorizer.transform([text])
    prob = model.predict_proba(text_vec)[0][1]  # class 1 = phishing

    # ìœ„í—˜ ë‹¨ì–´ í¬í•¨ ì‹œ í™•ë¥  ë³´ì •
    danger_count = sum(word in text for word in danger_words)
    if danger_count > 0:
        prob = min(prob * (1.2 + 0.1 * danger_count), 1.0)

    return prob * 100  # %

# -------------------------------------------------------
# ğŸ” KoBERT ì˜ˆì¸¡
# -------------------------------------------------------
def predict_kobert(text, tokenizer, model):
    inputs = tokenizer(
        text,
        truncation=True,
        padding="max_length",
        max_length=MAX_LEN,
        return_tensors="pt"
    ).to(DEVICE)

    if "token_type_ids" in inputs:
        inputs.pop("token_type_ids")

    with torch.no_grad():
        outputs = model(**inputs)
        probs = torch.nn.functional.softmax(outputs.logits, dim=1)[0]
        phishing_prob = probs[1].item() * 100

    return phishing_prob

# -------------------------------------------------------
# âš¡ í†µí•© ì˜ˆì¸¡ ë¡œì§
# -------------------------------------------------------
def unified_prediction(text, tfidf_model, vectorizer, tokenizer, kobert_model, danger_words):
    tfidf_prob = predict_tfidf(text, tfidf_model, vectorizer, danger_words)
    print(f"\nâš¡ TF-IDF ì˜ˆì¸¡ í™•ë¥ : {tfidf_prob:.2f}%")

    # TF-IDF ê²°ê³¼ê°€ 50% ì´ìƒì´ë©´ KoBERT ì‹¤í–‰
    if tfidf_prob >= 50:
        kobert_prob = predict_kobert(text, tokenizer, kobert_model)
        print(f"ğŸ§  KoBERT ì˜ˆì¸¡ í™•ë¥ : {kobert_prob:.2f}%")
        final_prob = (tfidf_prob * 0.6) + (kobert_prob * 0.4)
    else:
        final_prob = tfidf_prob

    label = "âš ï¸ ë³´ì´ìŠ¤í”¼ì‹± ì˜ì‹¬" if final_prob >= 50 else "âœ… ì •ìƒ í†µí™”"

    print(f"\nğŸ’¬ ì…ë ¥ ë¬¸ì¥: {text}")
    print(f"ğŸ¯ ìµœì¢… íŒë³„ ê²°ê³¼: {label} ({final_prob:.2f}% í™•ë¥ )")

    if final_prob >= 70:
        print("ğŸš¨ ì¶”ê°€ ê²€ì¦ ê¶Œì¥: ê³ ìœ„í—˜ ë¬¸ì¥ìœ¼ë¡œ ê°ì§€ë˜ì—ˆìŠµë‹ˆë‹¤.\n")

# -------------------------------------------------------
# ğŸ§  ì‹¤í–‰ ë£¨í”„
# -------------------------------------------------------
if __name__ == "__main__":
    print("ğŸš€ í•˜ì´ë¸Œë¦¬ë“œ ë³´ì´ìŠ¤í”¼ì‹± íƒì§€ ì‹œìŠ¤í…œ ì‹œì‘\n")

    # ëª¨ë¸ ë¡œë“œ
    tfidf_model, vectorizer = load_tfidf_model()
    tokenizer, kobert_model = load_kobert_model()
    danger_words = load_danger_words()

    # ì‹¤ì‹œê°„ ì˜ˆì¸¡ ë£¨í”„
    while True:
        text = input("\nğŸ“ ë¬¸ì¥ì„ ì…ë ¥í•˜ì„¸ìš” (ì¢…ë£Œ: exit): ").strip()
        if text.lower() == "exit":
            print("ğŸ‘‹ ì‹œìŠ¤í…œì„ ì¢…ë£Œí•©ë‹ˆë‹¤.")
            break

        unified_prediction(text, tfidf_model, vectorizer, tokenizer, kobert_model, danger_words)
