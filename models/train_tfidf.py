# file: models/train_tfidf_v3.py

import os
import joblib
import numpy as np
import pandas as pd
from datetime import datetime
from sklearn.model_selection import train_test_split
from sklearn.feature_extraction.text import TfidfVectorizer
from sklearn.ensemble import RandomForestClassifier, VotingClassifier
from sklearn.linear_model import LogisticRegression
from sklearn.metrics import classification_report, accuracy_score

# -------------------------------------------------------
# 1ï¸âƒ£ ê²½ë¡œ ì„¤ì •
# -------------------------------------------------------
BASE_DIR = os.path.dirname(os.path.dirname(os.path.abspath(__file__)))
DATA_PATH = os.path.join(BASE_DIR, "data", "processed", "cleaned_dataset.csv")
DANGER_PATH = os.path.join(BASE_DIR, "data", "processed", "danger_words.txt")
OUTPUT_DIR = os.path.join(BASE_DIR, "outputs")
MODEL_DIR = os.path.join(OUTPUT_DIR, "models")
TOKENIZER_DIR = os.path.join(OUTPUT_DIR, "tokenizer")

os.makedirs(MODEL_DIR, exist_ok=True)
os.makedirs(TOKENIZER_DIR, exist_ok=True)

# -------------------------------------------------------
# 2ï¸âƒ£ ë°ì´í„° ë¡œë“œ
# -------------------------------------------------------
df = pd.read_csv(DATA_PATH)
df["text"] = df["text"].astype(str)

X = df["text"]
y = df["label"]

X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)
print(f"ğŸ“ Train: {len(X_train)} / Test: {len(X_test)}")

# -------------------------------------------------------
# 3ï¸âƒ£ ìœ„í—˜ ë‹¨ì–´ ë¦¬ìŠ¤íŠ¸ ë¶ˆëŸ¬ì˜¤ê¸°
# -------------------------------------------------------
if os.path.exists(DANGER_PATH):
    with open(DANGER_PATH, "r", encoding="utf-8") as f:
        danger_words = [line.strip() for line in f.readlines()]
else:
    danger_words = []

print(f"âš ï¸ ìœ„í—˜ ë‹¨ì–´ {len(danger_words)}ê°œ ë¡œë“œ ì™„ë£Œ")

# -------------------------------------------------------
# 4ï¸âƒ£ TF-IDF ë²¡í„°í™”
# -------------------------------------------------------
vectorizer = TfidfVectorizer(
    max_features=10000,
    ngram_range=(1, 2),
    min_df=1,
    stop_words=["ì„", "ë¥¼", "ì´", "ê°€", "ì€", "ëŠ”", "ì—ì„œ", "ìœ¼ë¡œ", "ì—ê²Œ"]
)
X_train_tfidf = vectorizer.fit_transform(X_train)
X_test_tfidf = vectorizer.transform(X_test)
print(f"âœ… TF-IDF vectorized: {X_train_tfidf.shape[1]} features")

# -------------------------------------------------------
# 5ï¸âƒ£ ëª¨ë¸ êµ¬ì„± (Voting ì•™ìƒë¸”)
# -------------------------------------------------------
log_reg = LogisticRegression(max_iter=300, class_weight="balanced")
rf = RandomForestClassifier(n_estimators=250, random_state=42, class_weight="balanced")

model = VotingClassifier(
    estimators=[('lr', log_reg), ('rf', rf)],
    voting='soft'  # í™•ë¥  ê¸°ë°˜ ì•™ìƒë¸”
)
model.fit(X_train_tfidf, y_train)
print("âœ… VotingClassifier í•™ìŠµ ì™„ë£Œ")

# -------------------------------------------------------
# 6ï¸âƒ£ ì˜ˆì¸¡ + ìœ„í—˜ ë‹¨ì–´ ê°€ì¤‘ì¹˜ ì ìš©
# -------------------------------------------------------
base_probs = model.predict_proba(X_test_tfidf)[:, 1]

def danger_word_boost(text, base_prob):
    danger_count = sum(word in text for word in danger_words)
    if danger_count > 0:
        # ìœ„í—˜ ë‹¨ì–´ê°€ ë§ì„ìˆ˜ë¡ ê°€ì¤‘ì¹˜ ì¦ê°€
        boosted_prob = min(base_prob * (1.2 + 0.06 * danger_count), 1.0)
        return boosted_prob
    return base_prob

adjusted_probs = np.array([
    danger_word_boost(t, p) for t, p in zip(X_test, base_probs)
])

y_pred = (adjusted_probs >= 0.5).astype(int)

# -------------------------------------------------------
# 7ï¸âƒ£ í‰ê°€
# -------------------------------------------------------
print("\nğŸ“Š ë¶„ë¥˜ ë¦¬í¬íŠ¸:\n", classification_report(y_test, y_pred))
acc = accuracy_score(y_test, y_pred)
print(f"ğŸ¯ ìµœì¢… ì •í™•ë„: {acc:.4f}")

# -------------------------------------------------------
# 8ï¸âƒ£ ì €ì¥
# -------------------------------------------------------
timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
joblib.dump(model, os.path.join(MODEL_DIR, f"tfidf_hybrid_{timestamp}.pkl"))
joblib.dump(vectorizer, os.path.join(TOKENIZER_DIR, f"tfidf_vectorizer_{timestamp}.pkl"))

print(f"\nğŸ’¾ ëª¨ë¸ ì €ì¥ ì™„ë£Œ: {MODEL_DIR}")
print(f"ğŸ’¾ ë²¡í„° ì €ì¥ ì™„ë£Œ: {TOKENIZER_DIR}")
print("âœ… í•™ìŠµ ì™„ë£Œ: TF-IDF + VotingClassifier + ìœ„í—˜ë‹¨ì–´ê°€ì¤‘ Hybrid")
