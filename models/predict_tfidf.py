# file: models/predict_tfidf_v3.py

import os
import joblib
import numpy as np

# -------------------------------------------------------
# 1ï¸âƒ£ ê²½ë¡œ ì„¤ì •
# -------------------------------------------------------
BASE_DIR = os.path.dirname(os.path.dirname(os.path.abspath(__file__)))
MODEL_DIR = os.path.join(BASE_DIR, "outputs", "models")
TOKENIZER_DIR = os.path.join(BASE_DIR, "outputs", "tokenizer")
DANGER_PATH = os.path.join(BASE_DIR, "data", "processed", "danger_words.txt")

# -------------------------------------------------------
# 2ï¸âƒ£ ê°€ìž¥ ìµœì‹  ëª¨ë¸ê³¼ ë²¡í„° ë¶ˆëŸ¬ì˜¤ê¸°
# -------------------------------------------------------
def get_latest_file(directory, prefix):
    files = [f for f in os.listdir(directory) if f.startswith(prefix)]
    if not files:
        raise FileNotFoundError(f"{directory} ì•ˆì— {prefix} ê´€ë ¨ íŒŒì¼ì´ ì—†ìŠµë‹ˆë‹¤.")
    latest = max(files, key=lambda x: os.path.getctime(os.path.join(directory, x)))
    return os.path.join(directory, latest)

model_path = get_latest_file(MODEL_DIR, "tfidf_hybrid")
vectorizer_path = get_latest_file(TOKENIZER_DIR, "tfidf_vectorizer")

model = joblib.load(model_path)
vectorizer = joblib.load(vectorizer_path)

print(f"âœ… ëª¨ë¸ ë¡œë“œ ì™„ë£Œ: {os.path.basename(model_path)}")
print(f"âœ… ë²¡í„° ë¡œë“œ ì™„ë£Œ: {os.path.basename(vectorizer_path)}")

# -------------------------------------------------------
# 3ï¸âƒ£ ìœ„í—˜ ë‹¨ì–´ ë¦¬ìŠ¤íŠ¸ ë¡œë“œ
# -------------------------------------------------------
if os.path.exists(DANGER_PATH):
    with open(DANGER_PATH, "r", encoding="utf-8") as f:
        danger_words = [line.strip() for line in f.readlines()]
else:
    danger_words = []
print(f"âš ï¸ ìœ„í—˜ ë‹¨ì–´ {len(danger_words)}ê°œ ë¡œë“œ ì™„ë£Œ")

# -------------------------------------------------------
# 4ï¸âƒ£ ì˜ˆì¸¡ í•¨ìˆ˜
# -------------------------------------------------------
def predict_text_tfidf(text: str):
    text_tfidf = vectorizer.transform([text])
    prob = model.predict_proba(text_tfidf)[0][1]  # í´ëž˜ìŠ¤ 1 = í”¼ì‹±

    # ìœ„í—˜ ë‹¨ì–´ í¬í•¨ ì‹œ í™•ë¥  ë³´ì •
    danger_count = sum(word in text for word in danger_words)
    if danger_count > 0:
        prob = min(prob * (1.2 + 0.1 * danger_count), 1.0)

    label = "ë³´ì´ìŠ¤í”¼ì‹± ì˜ì‹¬" if prob >= 0.5 else "ì •ìƒ"

    print("\nðŸ’¬ ìž…ë ¥ ë¬¸ìž¥:", text)
    print(f"ðŸŽ¯ ì˜ˆì¸¡ ê²°ê³¼: {label} ({prob * 100:.2f}% í™•ë¥ )")

    # ì¶”ê°€ íŒë³„ ì•ˆë‚´
    if prob >= 0.7:
        print("âš ï¸ ì¶”ê°€ íŒë³„ í•„ìš”: KoBERT ëª¨ë¸ë¡œ ì •ë°€ ê²€ì¦ì„ ê¶Œìž¥í•©ë‹ˆë‹¤.")

# -------------------------------------------------------
# 5ï¸âƒ£ ì‹¤í–‰ ë£¨í”„
# -------------------------------------------------------
if __name__ == "__main__":
    print("\nðŸ“ž ë¬¸ìž¥ì„ ìž…ë ¥í•˜ì„¸ìš” (ì¢…ë£Œ: exit):")
    while True:
        text = input("\n> ")
        if text.lower() == "exit":
            break
        predict_text_tfidf(text)
