#ì¶”í›„ íŒë³„ì„ ìœ„í•œ ë‹¨ì–´ ë¦¬ìŠ¤íŠ¸ ì œìž‘

# file: preprocessing/make_danger_word.py

import pandas as pd
from collections import Counter
import re
import os

# ë°ì´í„° ê²½ë¡œ
BASE_DIR = os.path.dirname(os.path.dirname(os.path.abspath(__file__)))
DATA_PATH = os.path.join(BASE_DIR, "data", "processed", "cleaned_dataset.csv")
OUTPUT_PATH = os.path.join(BASE_DIR, "data", "processed", "danger_words.txt")

def clean_text(text):
    text = str(text)
    text = re.sub(r"[^ê°€-íž£0-9\s]", "", text)
    text = re.sub(r"\s+", " ", text).strip()
    return text

def make_danger_wordlist(threshold=3):
    print("ðŸ“˜ ìœ„í—˜ ë‹¨ì–´ ë¦¬ìŠ¤íŠ¸ ìƒì„± ì¤‘...")
    df = pd.read_csv(DATA_PATH)
    df["text"] = df["text"].apply(clean_text)

    # ë³´ì´ìŠ¤í”¼ì‹±(ë¼ë²¨=1) í…ìŠ¤íŠ¸ë§Œ ì‚¬ìš©
    phishing_texts = df[df["label"] == 1]["text"]

    # ë‹¨ì–´ í† í°í™”
    words = []
    for text in phishing_texts:
        words.extend(text.split())

    # ë‹¨ì–´ ë¹ˆë„ ê³„ì‚°
    counter = Counter(words)
    danger_words = [word for word, count in counter.items() if count >= threshold]

    # ì €ìž¥
    with open(OUTPUT_PATH, "w", encoding="utf-8") as f:
        for w in sorted(danger_words):
            f.write(w + "\n")

    print(f"âœ… ìœ„í—˜ ë‹¨ì–´ {len(danger_words)}ê°œ ì €ìž¥ ì™„ë£Œ â†’ {OUTPUT_PATH}")
    return danger_words

if __name__ == "__main__":
    make_danger_wordlist(threshold=3)
